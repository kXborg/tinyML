{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21d0e314-f706-4e5e-89eb-36bffed5082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b52850b0-f882-4c32-b748-86c94d0c04e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "digits = load_digits()\n",
    "X = digits.images / 16.0\n",
    "y = digits.target.reshape(-1, 1)\n",
    "\n",
    "# One-hot encode labels\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "# Flatten (8x8 â†’ 64 features)\n",
    "X = X.reshape(len(X), -1)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1106856-cbcc-4e71-add6-c62028a3c200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigger model (~19k params)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\", input_shape=(64,)),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ce6c546-fffd-4e0e-b97b-685e01bfdcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "41/41 [==============================] - 2s 8ms/step - loss: 1.8171 - accuracy: 0.4671 - val_loss: 1.3512 - val_accuracy: 0.6667\n",
      "Epoch 2/30\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.8945 - accuracy: 0.7927 - val_loss: 0.5654 - val_accuracy: 0.8611\n",
      "Epoch 3/30\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.9010 - val_loss: 0.3261 - val_accuracy: 0.9097\n",
      "Epoch 4/30\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2820 - accuracy: 0.9335 - val_loss: 0.2646 - val_accuracy: 0.9097\n",
      "Epoch 5/30\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.2081 - accuracy: 0.9513 - val_loss: 0.2237 - val_accuracy: 0.9167\n",
      "Epoch 6/30\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.1640 - accuracy: 0.9652 - val_loss: 0.1806 - val_accuracy: 0.9444\n",
      "Epoch 7/30\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.1575 - accuracy: 0.9575 - val_loss: 0.1693 - val_accuracy: 0.9306\n",
      "Epoch 8/30\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.1234 - accuracy: 0.9683 - val_loss: 0.1628 - val_accuracy: 0.9444\n",
      "Epoch 9/30\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.1077 - accuracy: 0.9706 - val_loss: 0.1341 - val_accuracy: 0.9444\n",
      "Epoch 10/30\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0868 - accuracy: 0.9814 - val_loss: 0.2009 - val_accuracy: 0.9375\n",
      "Epoch 11/30\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0768 - accuracy: 0.9807 - val_loss: 0.1434 - val_accuracy: 0.9306\n",
      "Epoch 12/30\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.9853 - val_loss: 0.1312 - val_accuracy: 0.9444\n",
      "Epoch 13/30\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0629 - accuracy: 0.9838 - val_loss: 0.1254 - val_accuracy: 0.9514\n",
      "Epoch 14/30\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0508 - accuracy: 0.9899 - val_loss: 0.1050 - val_accuracy: 0.9583\n",
      "Epoch 15/30\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0480 - accuracy: 0.9876 - val_loss: 0.1437 - val_accuracy: 0.9444\n",
      "Epoch 16/30\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 0.9923 - val_loss: 0.1228 - val_accuracy: 0.9444\n",
      "Epoch 17/30\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0389 - accuracy: 0.9915 - val_loss: 0.1198 - val_accuracy: 0.9514\n",
      "Epoch 18/30\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0303 - accuracy: 0.9954 - val_loss: 0.1067 - val_accuracy: 0.9306\n",
      "Epoch 19/30\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0253 - accuracy: 0.9961 - val_loss: 0.1129 - val_accuracy: 0.9444\n",
      "Epoch 20/30\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0239 - accuracy: 0.9969 - val_loss: 0.0842 - val_accuracy: 0.9722\n",
      "Epoch 21/30\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0218 - accuracy: 0.9969 - val_loss: 0.1189 - val_accuracy: 0.9444\n",
      "Epoch 22/30\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0187 - accuracy: 0.9969 - val_loss: 0.1041 - val_accuracy: 0.9583\n",
      "Epoch 23/30\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.0176 - accuracy: 0.9977 - val_loss: 0.1111 - val_accuracy: 0.9514\n",
      "Epoch 24/30\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 0.9977 - val_loss: 0.1007 - val_accuracy: 0.9514\n",
      "Epoch 25/30\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 0.9985 - val_loss: 0.1106 - val_accuracy: 0.9444\n",
      "Epoch 26/30\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9985 - val_loss: 0.0922 - val_accuracy: 0.9514\n",
      "Epoch 27/30\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0951 - val_accuracy: 0.9444\n",
      "Epoch 28/30\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9992 - val_loss: 0.0872 - val_accuracy: 0.9583\n",
      "Epoch 29/30\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 0.9444\n",
      "Epoch 30/30\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0876 - val_accuracy: 0.9653\n",
      "Test Accuracy: 0.9806\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,986\n",
      "Trainable params: 18,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, batch_size=32,\n",
    "                    validation_split=0.1, verbose=1)\n",
    "\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fc573fe-6707-4802-864b-42740372ec55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\kukil\\AppData\\Local\\Temp\\tmp_bgttq60\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kukil\\.conda\\envs\\tinyML\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    }
   ],
   "source": [
    "# Representative dataset for int8 quantization\n",
    "def representative_dataset():\n",
    "    for i in range(len(X_train)):\n",
    "        yield [X_train[i:i+1].astype(np.float32)]\n",
    "\n",
    "# Convert to fully int8\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save fully int8 TFLite model\n",
    "with open(\"digits_model_19k.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "820e7772-60fe-4005-a635-5577f3a614f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!xxd -i digits_model_quant_19k.tflite > digits_model_quant_19k.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6d252f7-3e68-4aa1-b9a8-fde8f21cfc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serving_default_dense_input:0 <class 'numpy.int8'>\n",
      "sequential/dense_3/BiasAdd/ReadVariableOp <class 'numpy.int32'>\n",
      "sequential/dense_3/MatMul <class 'numpy.int8'>\n",
      "sequential/dense_2/BiasAdd/ReadVariableOp <class 'numpy.int32'>\n",
      "sequential/dense_2/MatMul <class 'numpy.int8'>\n",
      "sequential/dense_1/BiasAdd/ReadVariableOp <class 'numpy.int32'>\n",
      "sequential/dense_1/MatMul <class 'numpy.int8'>\n",
      "sequential/dense/BiasAdd/ReadVariableOp <class 'numpy.int32'>\n",
      "sequential/dense/MatMul <class 'numpy.int8'>\n",
      "sequential/dense/MatMul;sequential/dense/Relu;sequential/dense/BiasAdd <class 'numpy.int8'>\n",
      "sequential/dense_1/MatMul;sequential/dense_1/Relu;sequential/dense_1/BiasAdd <class 'numpy.int8'>\n",
      "sequential/dense_2/MatMul;sequential/dense_2/Relu;sequential/dense_2/BiasAdd <class 'numpy.int8'>\n",
      "sequential/dense_3/MatMul;sequential/dense_3/BiasAdd <class 'numpy.int8'>\n",
      "StatefulPartitionedCall:0 <class 'numpy.int8'>\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"digits_model_19k.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "for detail in interpreter.get_tensor_details():\n",
    "    print(detail['name'], detail['dtype'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52531447-5acf-42c4-9b4c-a2db371a8035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinyML",
   "language": "python",
   "name": "tinyml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
